#!/usr/bin/env python
# coding: utf-8

# In[10]:


import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from random import randint
from PIL import Image
import torch
import os
import math
import random
import numpy as np
from random import randint


# In[17]:


def filenameToPILImage(x): return Image.open(x)


img_size = 32

# no augmentation


def get_transforms(img_size=32, norm_mu=[0.449], norm_sig=[0.226]):
    return transforms.Compose([
        filenameToPILImage,
        transforms.Resize((img_size, img_size)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomAffine(degrees=5, translate=(0.2, 0.05)),
        transforms.ToTensor(),
        transforms.Normalize(norm_mu, norm_sig)
    ])


# In[18]:


class DepthMapDataset(Dataset):
    def __init__(self, generated_depth_dir, mode, gt_depth_dir='', vid_len=10, total_len=11):
        """
        generated_depth_dir stores the depth images generated by CDCNpp
        gt_depth_dir stores the depth images generated by PRNet

        input of 3DCNN: images in generated_depth_dir
        output of 3DCNN: the last image in gt_depth_dir
        """
        assert mode in [
            'train', 'valid', 'test'], 'only train mode, valid mode and test mode are avalible'
        if mode != 'test':
            assert gt_depth_dir != '', 'We need ground truth depth map for training and validating'

        self.generated_depth_dir = generated_depth_dir
        self.gt_depth_dir = gt_depth_dir
        self.mode = mode
        self.vid_len = vid_len
        self.total_len = total_len

        self.meta_data = sorted(os.listdir(generated_depth_dir))
        self.trans = get_transforms()

        # the ground truth is not available
        if mode == 'valid':
            self.meta_data.remove('1_1_22_3')

        print("Depth mag dataset is created!")
        print(f"Spec: \n mode:{self.mode} \n video length:{self.vid_len}")

    def __len__(self):
        return len(self.meta_data)

    def __getitem__(self, idx):
        video_path = os.path.join(
            self.generated_depth_dir, self.meta_data[idx])
        frame_names = sorted(os.listdir(video_path))

        assert len(
            frame_names) >= self.vid_len, "vid_len is too large for the dataset!"

        # set seed for this loading
        seed = randint(0, 2147483647)
        self.seed = seed

        # load frames
        data = torch.empty(1, self.vid_len, img_size, img_size)
        sample_list = sorted(random.sample(
            range(0, self.total_len), self.vid_len))

        random.seed(seed)
        torch.manual_seed(seed)

        for i in range(self.vid_len):
            random.seed(seed)
            torch.manual_seed(seed)
            data[:, i, :, :] = self.trans(os.path.join(
                video_path, frame_names[sample_list[i]]))

        if self.mode == 'test':
            return data

        # set label
        label = torch.tensor(1) if self.meta_data[idx].split(
            '_')[-1] == '1' else torch.tensor(0)
        self.label = label

        # set ground truth binary mask
        binary_mask = self._get_binary_mask(idx, sample_list)

        return data, binary_mask, label

    def _get_binary_mask(self, idx, sample_list):
        # Get binary mask from GT depth image
        try:
            # fake
            if self.label == 0:
                binary_mask = np.zeros((32, 32))
                binary_mask = torch.FloatTensor(binary_mask)
                return binary_mask

            dep_video_path = os.path.join(
                self.gt_depth_dir, self.meta_data[idx])
            frame_names = sorted(os.listdir(dep_video_path))
            i = -1  # use the last one as GT
            dep_img_path = os.path.join(
                dep_video_path, frame_names[sample_list[i]])

            dep_img = self.trans(dep_img_path)
            binary_mask = torch.FloatTensor(dep_img).squeeze(0)

            return binary_mask

        except IndexError:
            # images failed to obtain depth image from PRnet -> use zeros by default
            binary_mask = np.zeros((32, 32))
            return torch.FloatTensor(binary_mask)
